{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed representations\n",
    "\n",
    "\n",
    "1. Sparse features  \n",
    "    1.1 Hashing trick  \n",
    "    1.2 Categorial features  \n",
    "    \n",
    "    Note about semi-supervised learning.\n",
    "    \n",
    "2. Word2vec  \n",
    "    2.1 skip-gram model  \n",
    "    2.2 continious bag of words model  \n",
    "    2.3 Co-occurence matrix  \n",
    "    2.4 Glove    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Sparse features\n",
    "### 1.1 Hashing trick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically it is a substution (string_token) -> hash(string_token) of fixed size  \n",
    "    \n",
    "Hello, polynomial hash for strings and MurmurHash3 (used in sklearn)  \n",
    "\n",
    "Pros:\n",
    "    1. extrapolate on unseen words, scalable\n",
    "    2. reduce feature dimension\n",
    "Cons:\n",
    "    1. no inverse transform possible\n",
    "    2. collisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train logloss 0.559925312648\n",
      "test logloss 0.629119988516\n"
     ]
    }
   ],
   "source": [
    "# demonstrate on US airlines twitter dataset for sentiment analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn import model_selection\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "SEED = 1337\n",
    "\n",
    "\n",
    "df = pd.read_csv('../seminar_10/Tweets.csv')\n",
    "\n",
    "y = LabelEncoder().fit_transform(df.airline_sentiment)\n",
    "\n",
    "df_train, df_test, y_train, y_test = model_selection.train_test_split(df, y, test_size=0.25, \n",
    "                                                                      stratify=y, # WHY\n",
    "                                                                      random_state=SEED, \n",
    "                                                                      shuffle=True) # WHY\n",
    "\n",
    "# model v1\n",
    "# Simple BOW model, binary matrix  \n",
    "# Let's try to reduce number of features with hashing\n",
    "model1 = Pipeline([\n",
    "    ('text_vect', HashingVectorizer(analyzer='word', n_features=500, ngram_range=(1,1), norm=None, binary=True)),\n",
    "    ('logreg', LogisticRegressionCV(Cs=10, cv=3, scoring='neg_log_loss', n_jobs=-1, \n",
    "                                    multi_class='multinomial', random_state=SEED))\n",
    "])\n",
    "\n",
    "model1.fit(df_train.text, y_train)\n",
    "print('train logloss', metrics.log_loss(y_train, model1.predict_proba(df_train.text)))\n",
    "print('test logloss', metrics.log_loss(y_test, model1.predict_proba(df_test.text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Categorial features in linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "United            3822\n",
       "US Airways        2913\n",
       "American          2759\n",
       "Southwest         2420\n",
       "Delta             2222\n",
       "Virgin America     504\n",
       "Name: airline, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add categorial feature to our linear model with one-hot encoding\n",
    "\n",
    "# categorial features\n",
    "df.airline.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one-hot enc shape (10980, 6)\n",
      "train logloss 0.558588706479\n",
      "test logloss 0.627312575957\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "text_vec = HashingVectorizer(analyzer='word', n_features=500, ngram_range=(1,1), norm=None, \n",
    "                             binary=True)\n",
    "X1_train = text_vec.fit_transform(df_train.text).toarray()\n",
    "\n",
    "tmp_le = LabelEncoder()\n",
    "X2_train = tmp_le.fit_transform(df_train.airline.values).reshape(-1,1)\n",
    "\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "X2_train = enc.fit_transform(X2_train)\n",
    "print('one-hot enc shape', X2_train.shape)\n",
    "\n",
    "X_train = np.hstack([X1_train, X2_train])\n",
    "\n",
    "model2 = LogisticRegressionCV(Cs=10, cv=3, scoring='neg_log_loss', n_jobs=-1, \n",
    "                                    multi_class='multinomial', random_state=SEED)\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "X1_test = text_vec.transform(df_test.text).toarray()\n",
    "X2_test = tmp_le.transform(df_test.airline.values).reshape(-1,1)\n",
    "X2_test = enc.transform(X2_test)\n",
    "X_test = np.hstack([X1_test, X2_test])\n",
    "\n",
    "print('train logloss', metrics.log_loss(y_train, model2.predict_proba(X_train)))\n",
    "print('test logloss', metrics.log_loss(y_test, model2.predict_proba(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Word2vec\n",
    "![image](http://nlpx.net/wp/wp-content/uploads/2015/11/word2vec.png)\n",
    "### 2.1 Skip-gram model\n",
    "![image](https://i.stack.imgur.com/igSuE.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each word t predict surrounding words in a window of size m\n",
    "\n",
    "Objective is maximize probability of context words given the current center word:  \n",
    "    \n",
    "$J(\\theta) = \\prod^T_{t=1} \\prod_{-m \\le j \\le m; j != 0 }  p(w_{t+j} | w_t; \\theta)  \\rightarrow max $\n",
    "\n",
    "or negative log-likelihood:\n",
    "\n",
    "$J(\\theta) = -\\frac{1}{T}\\sum^T_{t=1} \\sum_{-m \\le j \\le m; j != 0 }  log p(w_{t+j} | w_t; \\theta)  \\rightarrow max $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p(w_{t+j} | w_t) = p(out | center) = \\frac{exp(u_{out}^T v_{center})}{\\sum_k=1^K exp(u_{k}^T v_{center})}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using negative sampling with k samples:   \n",
    "    \n",
    "$log p(w_{t+j} | w_t; \\theta) = log \\sigma(u_{outer}^T v_{center})  + \\sum_{i=1}^k E_{j ~ P(w)} [log \\sigma (-u_j^T v_{center})]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1          NaN             of   IN   O\n",
       "2          NaN  demonstrators  NNS   O\n",
       "3          NaN           have  VBP   O\n",
       "4          NaN        marched  VBN   O"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ner_dataset.csv', encoding='latin-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O        0.848215\n",
       "B-gpe    0.030297\n",
       "B-geo    0.024498\n",
       "I-per    0.020598\n",
       "B-org    0.017598\n",
       "B-per    0.015998\n",
       "B-tim    0.014899\n",
       "I-org    0.013999\n",
       "I-geo    0.003100\n",
       "B-art    0.002800\n",
       "I-gpe    0.002000\n",
       "I-art    0.002000\n",
       "I-tim    0.001300\n",
       "B-eve    0.001000\n",
       "I-eve    0.001000\n",
       "B-nat    0.000500\n",
       "I-nat    0.000200\n",
       "Name: Tag, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Tag.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10001/10001 [00:11<00:00, 891.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.3 s, sys: 88 ms, total: 11.3 s\n",
      "Wall time: 11.3 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tqdm import tqdm\n",
    "\n",
    "current = df.loc[0, 'Sentence #']\n",
    "for j in tqdm(range(df.shape[0])):\n",
    "    if pd.isnull(df.loc[j, 'Sentence #']):\n",
    "        df.loc[j, 'Sentence #'] = current\n",
    "    else:\n",
    "        current = df.loc[j, 'Sentence #']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10001, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_list = list(df.groupby('Sentence #').Word.agg(lambda col: list(col)).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.83 s, sys: 4 ms, total: 1.84 s\n",
      "Wall time: 648 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "\n",
    "w2v = Word2Vec(sentences_list, negative=5, size=100, iter=100,\n",
    "               sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('arrested', 0.7161649465560913),\n",
       " ('news', 0.5250526666641235),\n",
       " ('Bali', 0.49507197737693787),\n",
       " ('authorities', 0.48440536856651306),\n",
       " ('1995', 0.4536770284175873),\n",
       " ('Ramda', 0.44481196999549866),\n",
       " ('Indonesian', 0.429607629776001),\n",
       " ('men', 0.419624388217926),\n",
       " ('Muslim', 0.41935527324676514),\n",
       " ('religious', 0.41110479831695557)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar('police')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 CBOW model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![!image](http://chaoyangzhu.com/2017/08/19/Word2Vec-the-Skip-Gram-and-Continuous-Bag-of-Words-Model/CBOW.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$h = W^T x$  \n",
    "$x = [w_{j-m}, w_{j-m+1}, ... w_{j-1}, w_{j+1}, ..., w_{j+m}]$  \n",
    "\n",
    "$p(w_j | x) = \\frac{exp(v_j^T h)}{\\sum_k=1^K exp(v_k^T h)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 780 ms, sys: 4 ms, total: 784 ms\n",
      "Wall time: 286 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "\n",
    "w2v = Word2Vec(sentences_list, negative=5, size=100, iter=100,\n",
    "               sg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('arrested', 0.9197296500205994),\n",
       " ('they', 0.8160843849182129),\n",
       " ('one', 0.8109095096588135),\n",
       " ('They', 0.8108460903167725),\n",
       " ('men', 0.7938530445098877),\n",
       " ('Officials', 0.7803452014923096),\n",
       " ('news', 0.7786381244659424),\n",
       " ('Bali', 0.7746149897575378),\n",
       " ('Ramda', 0.773020327091217),\n",
       " ('reported', 0.7419112920761108)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar('police')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Co-occurence matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P_{ij}$ - occurance of ith word along with j in the window of size m\n",
    "\n",
    "Cons: \n",
    "1. Very high-dimensional, not used in practice\n",
    "2. Hard to add new words and docs\n",
    "\n",
    "Solution for 1:\n",
    "1. Use some dimension-reduction method, usually SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Singular Value Decomposition\n",
    "\n",
    "$M = U \\Sigma V$  \n",
    "$Mv = \\sigma u$  \n",
    "$M^{*}u = \\sigma v$   \n",
    "U, V are unitary matrices  \n",
    "$\\Sigma$ - diagonal\n",
    "\n",
    "\n",
    "$O(nm^2)$ for case n < m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Glove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$J(\\theta) = \\frac{1}{2} \\sum_{i,j=1}^W f(P_{ij})(u_i^T v_j - log P_{ij})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install glove-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from glove import Corpus, Glove\n",
    "\n",
    "\n",
    "# construct co-occurance matrix\n",
    "corpus = Corpus()\n",
    "corpus.fit(sentences_list, window=5)\n",
    "\n",
    "\n",
    "glove = Glove(no_components=100, learning_rate=0.05)\n",
    "glove.fit(corpus.matrix, epochs=100, no_threads=4, verbose=False)\n",
    "glove.add_dictionary(corpus.dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('have', 0.96584710117145967),\n",
       " ('been', 0.94980699423519754),\n",
       " ('now', 0.91982068464752376),\n",
       " ('arrested', 0.89106702413428185)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove.most_similar('police')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.06373107,  0.00660779,  0.00198552,  0.01588677, -0.04370594,\n",
       "        0.01726277,  0.03111042, -0.03803431,  0.01086599, -0.00552099,\n",
       "       -0.0255159 ,  0.02388672, -0.02132961,  0.04047212, -0.0048955 ,\n",
       "        0.00786338,  0.00681678,  0.02083918,  0.06618839, -0.00561955,\n",
       "        0.01100433, -0.02659185, -0.02236061, -0.01816501, -0.02355093,\n",
       "       -0.00503574, -0.0024676 , -0.02036608, -0.03039759,  0.01722127,\n",
       "        0.0005871 , -0.00363654,  0.01328764,  0.00019342,  0.03065761,\n",
       "       -0.00217669,  0.01583674, -0.03217559, -0.03417455,  0.0162312 ,\n",
       "       -0.04813819, -0.01857898,  0.04468576, -0.00634232,  0.00877675,\n",
       "        0.0330481 , -0.02542432,  0.02333535,  0.01009918, -0.03192986,\n",
       "        0.01421471, -0.01503508, -0.00372783,  0.01537362,  0.05988799,\n",
       "        0.04015709,  0.00135291,  0.00476957, -0.01157399, -0.02555511,\n",
       "        0.00330979,  0.04183831, -0.00037858, -0.01671695, -0.00691607,\n",
       "       -0.02183392,  0.01438478,  0.00939871, -0.02542321, -0.00190508,\n",
       "       -0.01433402,  0.00767718,  0.00325412, -0.05119858, -0.02876604,\n",
       "       -0.00504751, -0.0234834 , -0.05875956,  0.03094858,  0.00153722,\n",
       "        0.00192696,  0.01867008,  0.00636784,  0.02272087,  0.02002859,\n",
       "        0.00336152, -0.01156864, -0.00091745, -0.0398081 ,  0.0134999 ,\n",
       "       -0.01598697, -0.00260553,  0.00948103,  0.03599105, -0.00695896,\n",
       "        0.02190049, -0.02957949,  0.00880139,  0.00945124, -0.00232933])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove.word_vectors[glove.dictionary['police']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe058594128>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfaWUCiEa+kopFUI09JVSKoT8f+At5d9Rt4/1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe06118db70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.distplot([len(x) for x in sentences_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10001/10001 [00:34<00:00, 290.43it/s]\n"
     ]
    }
   ],
   "source": [
    "f_words = []\n",
    "f_pos = []\n",
    "y = []\n",
    "\n",
    "window = 3\n",
    "for t in tqdm(range(df.shape[0])):\n",
    "    start_sentence = df[df['Sentence #'] == df.loc[t, 'Sentence #']].index.min()\n",
    "    end_sentence = df[df['Sentence #'] == df.loc[t, 'Sentence #']].index.max()\n",
    "    \n",
    "    r_pos = []\n",
    "    r_words = []\n",
    "    \n",
    "    for i in range(t-window, t):\n",
    "        if i < start_sentence:\n",
    "            r_words.append(None)\n",
    "            r_pos.append(None)\n",
    "        else:\n",
    "            r_words.append(df.loc[i, 'Word'])\n",
    "            r_pos.append(df.loc[i, 'POS'])\n",
    "            \n",
    "            \n",
    "    for i in range(t+1, t+window+1):\n",
    "        if i > end_sentence:\n",
    "            r_words.append(None)\n",
    "            r_pos.append(None)\n",
    "        else:\n",
    "            r_words.append(df.loc[i, 'Word'])\n",
    "            r_pos.append(df.loc[i, 'POS'])\n",
    "            \n",
    "    f_words.append(r_words)\n",
    "    f_pos.append(r_pos)\n",
    "    \n",
    "    y.append(df.loc[t, 'Tag'])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
